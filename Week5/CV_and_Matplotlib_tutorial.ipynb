{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuUAgQFQlsJU"
   },
   "source": [
    "# Python for Computer Vision \n",
    "Adapted from 6.8300 / 6.8301 course from MIT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVOsLEGclsJZ"
   },
   "source": [
    "# Contents\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "- [Matplotlib (Plotting and Visualization)](#Matplotlib)\n",
    "    - Basic plots\n",
    "    - Figures\n",
    "      \n",
    "    \n",
    "- [OpenCV (Computer Vision)](#OpenCV)\n",
    "    - Reading images\n",
    "    - Channels, Image Formats, and using images as arrays\n",
    "    - Showing images\n",
    "    - Basic image operations - Resize, Color, and more\n",
    "    - Working with Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weMMc2WZlsJc"
   },
   "source": [
    "# Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gpvh7PPVlsJg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeE2XSFmmLLI"
   },
   "outputs": [],
   "source": [
    "expected_name = \"2023_PythonTutorial_6869.ipynb\"\n",
    "\n",
    "# Colab specific setup\n",
    "try:\n",
    "  from google.colab import drive\n",
    "\n",
    "except Exception:\n",
    "  # Local setup\n",
    "  rootpath = \".\"\n",
    "\n",
    "else:\n",
    "  drive.mount('/content/gdrive')\n",
    "  rootpath = '/content/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIkyPTQtlsNd"
   },
   "source": [
    "**NOTE:** Matrices in numpy MUST be rectangular. Unlike nested Python lists, which can have the first list contain 1 element, and the second list contain 3 elements, in a numpy matrix, all rows have to have the same length. In other words, the matrix cannot be \"jagged\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPGcM7iUlsOa"
   },
   "source": [
    "Unless you explicitly use `np.copy`, Reshapes and slices create *views* of your data - that is, they all reference the same data! So, since the variables are all aliases to the same data, changes to one will reflect in all the others! This is a double-edged sword that can boost your performance, but might catch you off guard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2qjvNr7lsSb"
   },
   "source": [
    "The basic mathematical operators (+, -, /, \\*, %) are treated as \"elementwise\" operators - they do something with each element. Which operands are used depends on a concept called \"broadcasting\". In practice - if you have two ndarrays of the same shape, then the operands will be corresponding elements in each ndarray. Otherwise, if possible (ie, dimension is length 1), the smaller ndarray/scalar is repeated to be the same size as the larger array.\n",
    "\n",
    "# Matplotlib\r\n",
    "\r\n",
    "Matplotlib is a plotting library. `matplotlib.pyplot` exposes a stateful, easy to use, plotting system.\r\n",
    "\r\n",
    "Documentation: https://matplotlib.org/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X04gLBijlsT2"
   },
   "source": [
    "### Plotting\n",
    "\n",
    "Let's make a simple 2d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYnaz3CilsT3"
   },
   "outputs": [],
   "source": [
    "# Compute the x and y coordinates for points on a sine curve\n",
    "x = np.arange(0, 3 * np.pi, 0.1)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Plot the points using matplotlib\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQWNg2MilsT6"
   },
   "source": [
    "With just a little bit of extra work we can easily plot multiple lines at once, and add a title, legend, and axis labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6pj9c2HlsT7"
   },
   "outputs": [],
   "source": [
    "y_sin = np.sin(x)\n",
    "y_cos = np.cos(x)\n",
    "\n",
    "# Plot the points using matplotlib\n",
    "plt.plot(x, y_sin)\n",
    "plt.plot(x, y_cos)\n",
    "plt.xlabel('x axis label')\n",
    "plt.ylabel('y axis label')\n",
    "plt.title('Sine and Cosine')\n",
    "plt.legend(['Sine', 'Cosine'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUmTvJD3lsT8"
   },
   "source": [
    "### Subplots\n",
    "\n",
    "You can plot different things in the same figure using the subplot function. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKlKQSeqlsT9"
   },
   "outputs": [],
   "source": [
    "# Compute the x and y coordinates for points on sine and cosine curves\n",
    "x = np.arange(0, 3 * np.pi, 0.1)\n",
    "y_sin = np.sin(x)\n",
    "y_cos = np.cos(x)\n",
    "\n",
    "# Set up a subplot grid that has height 2 and width 1,\n",
    "# and set the first such subplot as active.\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Make the first plot\n",
    "plt.plot(x, y_sin)\n",
    "plt.title('Sine')\n",
    "\n",
    "# Set the second subplot as active, and make the second plot.\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x, y_cos)\n",
    "plt.title('Cosine')\n",
    "\n",
    "# Show the figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfdV9IkflsT_"
   },
   "source": [
    "# OpenCV\n",
    "\n",
    "OpenCV is an extremely popular computer vision library built in C++, with many powerful tools for CV. It lets you read, write, and show images and videos, read from webcam streams, find matching keypoints between two images, and more.\n",
    "\n",
    "OpenCV is written in C++, however, there is a Python library that uses these optimized C++ libraries, and exposes an API using numpy arrays!\n",
    "\n",
    "We're going to work with images and videos here. We'll be downloading them automatically, but if you have any issues, you can get the files from this folder and manually upload them to colab with drag and drop:  https://drive.google.com/drive/folders/1wP7BLo6gKC13696GVjVdIK-aXcXpr4Ye?usp=share_link\n",
    "\n",
    "Let's import OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvZMt995lsUA"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIMKhkvFskTe"
   },
   "source": [
    "Let's start by fetching a test image and video that we'll be using in this section. For this, we use the `requests` package: a fairly straightforward way of fetching content from URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCjeTEIRlRYz"
   },
   "outputs": [],
   "source": [
    "# Let's download the image and video we'll be using!\n",
    "import requests\n",
    "\n",
    "img = requests.get(\"https://www.dropbox.com/s/8n5v2zp7cuwb0gx/phoenix.jpg?dl=1\").content\n",
    "with open('phoenix.jpg', 'wb') as handler:\n",
    "    handler.write(img)\n",
    "\n",
    "vid = requests.get(\"https://www.dropbox.com/s/f194zeyqbr00cjm/sample_video.mp4?dl=1\").content\n",
    "with open('sample_video.mp4', 'wb') as handler:\n",
    "    handler.write(vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GAUOSo4s3ce"
   },
   "source": [
    "The image and video should show up on your file explorer. If you're on colab, click the refresh files button if it's not popping up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFgfbGIAlsUD"
   },
   "source": [
    "## Reading, Writing, and Showing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKjPEnsTlsUD"
   },
   "source": [
    "### Reading\n",
    "\n",
    "You can use the `imread` function to read in an image from a filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhdy1tN_lsUE"
   },
   "outputs": [],
   "source": [
    "phoenix_image = cv2.imread(\"phoenix.jpg\")\n",
    "\n",
    "# Careful, if it can't find your image, cv2.imread silently fails and returns None!\n",
    "if phoenix_image is None:\n",
    "  raise Exception(\"The image was not found! Check that you can see it on colab's file explorer by clicking the files icon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J28iYBklsUF"
   },
   "source": [
    "Images in OpenCV are represented as numpy arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BklZk6RJlsUG"
   },
   "outputs": [],
   "source": [
    "type(phoenix_image), phoenix_image.shape, phoenix_image.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yrp_h0RllsUI"
   },
   "source": [
    "### Channels, Image Formats, and using images as arrays\n",
    "The shape of a color image is (height, width, colors BGR) \\\n",
    "While it may seem strange that the height is first, it's because OpenCV treats images as \"Rows\" and \"Columns\" of an image. The \"height\" of an image is the number of rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ik6aUO75lsUJ"
   },
   "outputs": [],
   "source": [
    "phoenix_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7XtSj29lsUN"
   },
   "source": [
    "You can see each pixel is represented by 3 values (uint8 means they are between 0 and 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUOUHsFdlsUQ"
   },
   "outputs": [],
   "source": [
    "phoenix_image[0,0] # Get the pixel located at (0,0) from the top left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzc0htGqlsUU"
   },
   "source": [
    "Color images consist of \"channels\" - each color we can render is some combination of red, green, and blue (OR, in the case of a grayscale image, gray).\n",
    "\n",
    "There are other sets of channels - you'll learn about these in the Color lecture!\n",
    "\n",
    "By default, color images are opened by OpenCV as BGR, meaning the values for a given pixel are ordered \"blue, green, red\".\n",
    "\n",
    "We can use the `cv2.cvtColor` function to change which color system our image is in. This will appear shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYFD7gb1lsUV"
   },
   "outputs": [],
   "source": [
    "phoenix_image_rgb = cv2.cvtColor(phoenix_image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaa3_J_flsUY"
   },
   "source": [
    "### Showing the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0QD2dOclsUZ"
   },
   "source": [
    "If you're running scripted Python (not Jupyter notebook) The `imshow` command will display an image. However, this doesn't work in jupyter notebook, so we'll use Matplotlib's `imshow` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZdpYNjTlsUZ"
   },
   "outputs": [],
   "source": [
    "# This line only works if you're running locally\n",
    "# cv2.imshow('test', phoenix_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1eFaTIelsUb"
   },
   "source": [
    "Matplotlib assumes images are in the **RGB** format. OpenCV assumes that images are in the **BGR** format. So, we'll convert colors before showing the image. Let's make a function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1M69bUGlsUc"
   },
   "outputs": [],
   "source": [
    "def imshow(image, *args, **kwargs):\n",
    "    if len(image.shape) == 3:\n",
    "      # Height, width, channels\n",
    "      # Assume BGR, do a conversion since\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "      # Height, width - must be grayscale\n",
    "      # convert to RGB, since matplotlib will plot in a weird colormap (instead of black = 0, white = 1)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    # Draw the image\n",
    "    plt.imshow(image, *args, **kwargs)\n",
    "    # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
    "    plt.axis('off')\n",
    "    # Make sure it outputs\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2-pNCzqlsUf"
   },
   "source": [
    "Let's show the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBlvKUMolsUg"
   },
   "outputs": [],
   "source": [
    "imshow(phoenix_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HnYFtCOlsUi"
   },
   "source": [
    "### Manipulating images\n",
    "\n",
    "#### Changing color spaces\n",
    "\n",
    "OpenCV exposes several functions to work with images. Let's use the `cvtColor` function to convert the color image to gray. Grayscale images do not have a third dimension, instead, each pixel has a luminosity (\"whiteness\") value between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtholCvhlsUj"
   },
   "outputs": [],
   "source": [
    "phoenix_gray = cv2.cvtColor(phoenix_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(\"Created BW image of shape\",phoenix_gray.shape)\n",
    "imshow(phoenix_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp2T7RjElsUl"
   },
   "source": [
    "We also can manipulate it by doing anything we would to a normal array. Let's make an image that includes the gray phoenix as the blue channel and red channels, and nothing in the green channels. (This is NOT the same as excluding the green channel from the original image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1Zo26CFlsUm"
   },
   "outputs": [],
   "source": [
    "empty_arr = np.zeros(phoenix_gray.shape, dtype=np.uint8)\n",
    "\n",
    "# Stack them, making the 3rd axis\n",
    "magenta_phoenix = np.stack([ phoenix_gray, empty_arr, phoenix_gray, ], axis=2)\n",
    "print(\"Created image of shape\",magenta_phoenix.shape)\n",
    "imshow(magenta_phoenix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKLPU5EilsUo"
   },
   "source": [
    "#### Resizing images\n",
    "\n",
    "We can also resize images using `resize`. This needs the output size. Note that these are image sizes, which are expressed as (width, height), NOT to be confused with their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvNxmeKylsUq"
   },
   "outputs": [],
   "source": [
    "image_height, image_width, image_num_channels = magenta_phoenix.shape\n",
    "new_height = image_height * 2\n",
    "new_width = image_width * 3\n",
    "\n",
    "# Resize it to 3x the width, and 2x the height, so we expect some distortion.\n",
    "# (To display it in the browser, the image is being scaled down anyway, so resizing it 2 x 2 will not be obvious)\n",
    "\n",
    "bigger_magenta_phoenix = cv2.resize(magenta_phoenix, (new_width, new_height))\n",
    "print(\"Resized to image of shape\",bigger_magenta_phoenix.shape)\n",
    "imshow(bigger_magenta_phoenix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjWQYjYVlsUt"
   },
   "source": [
    "### Writing an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VM0EQJhlsUt"
   },
   "source": [
    "The `imwrite` function can write out an image. Let's write out the image we just made, so we can use it later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uB7vl5ehlsUu"
   },
   "outputs": [],
   "source": [
    "output_path = \"./output_pinkphoenix.png\"\n",
    "cv2.imwrite(output_path, bigger_magenta_phoenix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCG0F5m7lsUw"
   },
   "source": [
    "We should be able to read that image directly from the file. Let's try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T79N7N7DlsUx"
   },
   "outputs": [],
   "source": [
    "test_read_output = cv2.imread(output_path)\n",
    "print(\"Read file of shape:\",test_read_output.shape, \"type\",test_read_output.dtype)\n",
    "imshow(test_read_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEVrCiEQlsUz"
   },
   "source": [
    "Everything works as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clG-u520rvjJ"
   },
   "source": [
    "### Working with Video\n",
    "\n",
    "A video is nothing more than a series of images. We can use the `VideoCapture` object to read videos from webcams, IP cameras, and files. Since we're working in the cloud, we'll use files.\n",
    "\n",
    "We can use the `VideoWriter` object to write videos to a file. (If you were working locally, you could use `cv2.imshow` to display it in real time)\n",
    "\n",
    "Let's use what we've learned so far to crop the video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laInONEvs1UJ"
   },
   "outputs": [],
   "source": [
    "# function to crop a given frame\n",
    "def crop_frame(frame, crop_size):\n",
    "  # We're given a frame, either gray or RGB, and a crop-size (w,h)\n",
    "  crop_w, crop_h = crop_size\n",
    "  # This is an array! We can slice it\n",
    "  # Take the first pixels along the height, and along the width\n",
    "  cropped = frame[:crop_h, :crop_w]\n",
    "  return cropped\n",
    "\n",
    "capture = cv2.VideoCapture('sample_video.mp4')\n",
    "\n",
    "crop_size = (600,400) # w,h\n",
    "output_path = 'output_cropped.mp4'\n",
    "# Use the MJPG format\n",
    "output_format = cv2.VideoWriter_fourcc('M','P','4','V')\n",
    "output_fps = 30\n",
    "cropped_output = cv2.VideoWriter(output_path, output_format, output_fps, crop_size)\n",
    "n = 0\n",
    "\n",
    "while True:\n",
    "  successful, next_frame = capture.read()\n",
    "  if not successful:\n",
    "    # No more frames to read\n",
    "    print(\"Processed %d frames\" % n)\n",
    "    break\n",
    "  # We have an input frame. Use our function to crop it.\n",
    "  output_frame = crop_frame(next_frame, crop_size)\n",
    "  # Write the output frame to the output video\n",
    "  cropped_output.write(output_frame)\n",
    "  n += 1\n",
    "  # Now we have an image! We can process that as we would.\n",
    "\n",
    "# We have to give up the file at the end.\n",
    "capture.release()\n",
    "cropped_output.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkDYJvPv6HKU"
   },
   "source": [
    "### Display the Video\n",
    "\n",
    "Unfortunately, it's rather difficult to display videos in Jupyter, so check your file explorer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXV5YxS7lsU2"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "All of these exercises are doable with the information you've been presented thus far.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLZxOOH-lsU3"
   },
   "source": [
    "## Exercise 1\n",
    "**Grading students**\n",
    "The class 6.869 has `num_students` students. Each student has `num_grades` grades, one for each assignment.\n",
    "The staff store our grades in a numpy ndarray, of shape `(num_students, num_grades)`. (Each row is a student, each column is an assignment)\n",
    "\n",
    "**(a)** Create an ndarray of the proper shape to hold the grades table, and fill it with the values `[0, num_students * num_grades)`, going left-to-right, then top-to-bottom.\n",
    "\n",
    "**(b)** We have a meeting with Julie, whose student index is `2`, and want to see how she's doing in the class. Use ndarray slicing to get an array containing all of her grades (index 2).\n",
    "\n",
    "**(c)** Phillip wants to know if PSet 4 (assignment index 4) is too hard. Use ndarray slicing to extract the whole classes grades for PSet 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4oSQJq1lsU4"
   },
   "outputs": [],
   "source": [
    "num_students = 4\n",
    "num_assignments = 5\n",
    "\n",
    "# Write your solution below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-YEM3t2lsU-"
   },
   "source": [
    "# Exercise 2\n",
    "**Pose Estimation** The 6.869 staff have developed a ground-breaking pose estimation network. The output of the network is a matrix of shape `(num_keypoints, 3)` (each row is a key point on the body, the columns are X,Y,Z). A \"joint\" is a connection between two keypoints, expressed as a matrix of shape `(num_joints, 2)`, (each row is a joint, the columns are START_KEYPOINT_INDEX and END_KEYPOINT_INDEX).\n",
    "\n",
    "**(a)** Create a matrix of joint starts, and another matrix of joint ends, each of shape `(num_joints, 3)`. The starts table should contain the position of the start of each joint (according to `position`)  \n",
    "\n",
    "**(b)** Create a matrix of joint-displacements, of shape `(num_joints, 3)`. Each row represents a joint. The columns should be the difference in X, Y, and Z between the start of the joint, and the end of the joint, respectively `(endX - startX, endY - startY, endZ-startZ)`.\n",
    "\n",
    "**(c)** Find the magnitude (length) of each of these displacement vectors, and output the results in an array of length `num_joints`. Remember the power operator is `**`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w028LM6llsU_"
   },
   "outputs": [],
   "source": [
    "num_keypoints = 7\n",
    "num_joints = 5\n",
    "\n",
    "\n",
    "# All Z's in one plane, but makes it easier to see XYZ vs Start/end\n",
    "keypoint_positions = np.array(\n",
    "    [\n",
    "        [0, 1, 0], #Head\n",
    "        [0, 0, 0], #Torso\n",
    "        [1, 0, 0], #Right Arm\n",
    "        [-1, 0, 0], #Left Arm\n",
    "        [0, -1, 0], #Lower ,Torso\n",
    "        [1, -2, 0], #Right Leg\n",
    "        [-1, -2, 0] #Left Leg\n",
    "    ]\n",
    ")\n",
    "\n",
    "#   O\n",
    "#  _|_\n",
    "#   |\n",
    "#  /\\\n",
    "joints = np.array([\n",
    "    # Head to torso\n",
    "    [0, 1],\n",
    "    # Torso to Right arm\n",
    "    [1, 2],\n",
    "    # Torso to Left Arm\n",
    "    [1, 3],\n",
    "    # Torso to Lower Torso\n",
    "    [3, 4],\n",
    "    # Lower Torso to Right Leg\n",
    "    [4, 5],\n",
    "    # Lower Torso to Left Leg\n",
    "    [4, 6]\n",
    "])\n",
    "\n",
    "\n",
    "# Write your solution below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHyGmaqu9kTd"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "**Edge detection** Our phoenix is lovely and bright - but what if we wanted to draw it? it might help to have the edges.\n",
    "\n",
    "**(a)** Load the image `phoenix.jpg`. Covert it to grayscale. \\\n",
    "**(b)** Use the scipy.signal.convolve2d (aliased as `conv2d`) to compute the convolution of the phoenix and the `kernel` (make sure to cast to a float32 between 0 and 1 first). Use imshow to show the results. Use `prep_to_draw` to convert a [0,1] BW image to a drawable image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZickyq-9n-9"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.signal\n",
    "\n",
    "conv2d = scipy.signal.convolve2d # assigning a shorter name for this function.\n",
    "\n",
    "# looks for horizontal edges\n",
    "horizontal_edge_detector = np.array(\n",
    "  [\n",
    "      [-1, 0, 1]\n",
    "  ]\n",
    ")\n",
    "\n",
    "box_blur_size = 15\n",
    "box_blur = np.ones((box_blur_size, box_blur_size)) / (box_blur_size ** 2)\n",
    "sharpen_kernel = np.array(\n",
    "    [\n",
    "        [0, -1, 0],\n",
    "        [-1, 5, -1],\n",
    "        [0,  -1, 0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "all_edge_detector = np.array(\n",
    "    [\n",
    "        [0, -1, 0],\n",
    "        [-1, 4, -1],\n",
    "        [0,  -1, 0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def prep_to_draw(img):\n",
    "  \"\"\" Function which takes in an image and processes it to display it.\n",
    "  \"\"\"\n",
    "  # Scale to 0,255\n",
    "  prepped = img * 255\n",
    "  # Clamp to [0, 255]\n",
    "  prepped = np.clip(prepped, 0, 255) # clips values < 0 to 0 and > 255 to 255.\n",
    "  prepped = prepped.astype(np.uint8)\n",
    "  return prepped\n",
    "\n",
    "# Write your solution below."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
